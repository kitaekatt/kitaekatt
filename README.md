# Hi, I'm Christina Norman

**AI/ML contributor** focused on LLM inference optimization and tooling. Active contributor to [vLLM](https://github.com/vllm-project/vllm) and [Hugging Face Transformers](https://github.com/huggingface/transformers).

Previously: Founder of Elodie Games | Design Lead at Riot Games (League of Legends, Wild Rift) | BioWare (Mass Effect 1-3)

## Current Focus

Building and improving LLM infrastructure—particularly GGUF model support, memory optimization, and inference performance for next-gen hardware like NVIDIA Blackwell.

## Open Source Contributions

### vLLM (High-throughput LLM Inference Engine)

**Merged:**
- [fix(gguf): Disable bfloat16 for GGUF on Blackwell](https://github.com/vllm-project/vllm/pull/30408)
- [fix(shm): Add memory barriers for cross-process shared memory](https://github.com/vllm-project/vllm/pull/30407)
- [Skip generation config fallback for GGUF to prevent hang](https://github.com/vllm-project/vllm/pull/30209)

**In Progress:**
- GGUF dtype auto-selection for Blackwell GPUs
- Gemma2/Gemma3 GGUF weight loading fixes
- Nemotron-H rotary positional embeddings
- Lazy tokenizer init to prevent semaphore leaks

### Hugging Face Transformers

- [Add attn_logit_softcapping to Gemma2/Gemma3 GGUF config](https://github.com/huggingface/transformers/pull/37749)

### Claude Code

Active contributor to Anthropic's Claude Code CLI—filing feature requests and bug reports to improve the AI coding agent experience.

## Tech Stack

<p>
  <img src="https://skillicons.dev/icons?i=python,typescript,cpp,pytorch,linux,git,github,neovim" />
</p>

## GitHub Stats

<p>
  <img src="https://github-readme-stats.vercel.app/api?username=kitaekatt&theme=transparent&show_icons=true&hide_border=true&count_private=true" />
</p>

## Connect

- **X/Twitter:** [@truffle](https://x.com/truffle)
- **Location:** Austin, Texas
